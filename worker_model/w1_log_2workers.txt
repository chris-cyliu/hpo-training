C:\Users\b148848\AppData\Local\Microsoft\WindowsApps\ubuntu.exe run "export PYTHONUNBUFFERED=1 && export PYTHONIOENCODING=UTF-8 && export \"PYTHONPATH=/mnt/d/GitRepository/GRPC-Model:/mnt/d/Program Files/JetBrains/PyCharm 2019.2.2/helpers/pycharm_matplotlib_backend:/mnt/d/Program Files/JetBrains/PyCharm 2019.2.2/helpers/pycharm_display\" && export PYCHARM_HOSTED=1 && export PYCHARM_DISPLAY_PORT=63342 && cd /mnt/d/GitRepository/GRPC-Model/worker_model && /home/vincent/miniconda3/envs/build/bin/python /mnt/d/GitRepository/GRPC-Model/worker_model/w1.py"
2019-11-12 16:35:25.992139: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz
2019-11-12 16:35:25.993103: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fffc4524a10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-11-12 16:35:25.993232: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
E1112 16:35:25.997643400   19168 socket_utils_common_posix.cc:198] check for SO_REUSEPORT: {"created":"@1573547725.997629500","description":"Protocol not available","errno":92,"file":"external/grpc/src/core/lib/iomgr/socket_utils_common_posix.cc","file_line":175,"os_error":"Protocol not available","syscall":"getsockopt(SO_REUSEPORT)"}
E1112 16:35:25.997762900   19168 socket_utils_common_posix.cc:299] setsockopt(TCP_USER_TIMEOUT) Protocol not available
2019-11-12 16:35:25.997992: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12345, 1 -> localhost:23456}
2019-11-12 16:35:26.001203: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:371] Started server with target: grpc://localhost:23456
INFO:tensorflow:Enabled multi-worker collective ops with available devices: ['/job:worker/replica:0/task:1/device:CPU:0', '/job:worker/replica:0/task:1/device:XLA_CPU:0']
INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:1',)
INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['localhost:12345', 'localhost:23456']}, task_type = 'worker', task_id = 1, num_workers = 2, local_devices = ('/job:worker/task:1',), communication = CollectiveCommunication.AUTO
INFO:tensorflow:TF_CONFIG environment variable: {'cluster': {'worker': ['localhost:12345', 'localhost:23456']}, 'task': {'type': 'worker', 'index': 1}}
INFO:tensorflow:Initializing RunConfig with distribution strategies.
INFO:tensorflow:RunConfig initialized for Distribute Coordinator with INDEPENDENT_WORKER mode
INFO:tensorflow:Using config: {'_model_dir': './estimator/multiworker', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f2e334f84d0>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['localhost:12345', 'localhost:23456']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': 'independent_worker'}
INFO:tensorflow:Running `train_and_evaluate` with Distribute Coordinator.
INFO:tensorflow:Running Distribute Coordinator with mode = 'independent_worker', cluster_spec = {'worker': ['localhost:12345', 'localhost:23456']}, task_type = 'worker', task_id = 1, environment = None, rpc_layer = 'grpc'
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:1',)
INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['localhost:12345', 'localhost:23456']}, task_type = 'worker', task_id = 1, num_workers = 2, local_devices = ('/job:worker/task:1',), communication = CollectiveCommunication.AUTO
INFO:tensorflow:Using MirroredStrategy with devices ('/job:worker/task:1',)
INFO:tensorflow:MultiWorkerMirroredStrategy with cluster_spec = {'worker': ['localhost:12345', 'localhost:23456']}, task_type = 'worker', task_id = 1, num_workers = 2, local_devices = ('/job:worker/task:1',), communication = CollectiveCommunication.AUTO
INFO:tensorflow:Updated config: {'_model_dir': './estimator/multiworker', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f2e334f8350>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['localhost:12345', 'localhost:23456']}), '_task_type': 'worker', '_task_id': 1, '_global_id_in_cluster': 1, '_master': 'grpc://localhost:23456', '_evaluation_master': 'grpc://localhost:23456', '_is_chief': False, '_num_ps_replicas': 0, '_num_worker_replicas': 2, '_distribute_coordinator_mode': 'independent_worker'}
INFO:tensorflow:The `input_fn` accepts an `input_context` which will be given by DistributionStrategy
WARNING:tensorflow:From /home/vincent/miniconda3/envs/build/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1634: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From /home/vincent/miniconda3/envs/build/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1634: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Collective batch_all_reduce: 6 all-reduces, num_workers = 2, communication_hint = AUTO
INFO:tensorflow:Collective batch_all_reduce: 6 all-reduces, num_workers = 2, communication_hint = AUTO
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_workers = 2, communication_hint = AUTO
INFO:tensorflow:Collective batch_all_reduce: 1 all-reduces, num_workers = 2, communication_hint = AUTO
WARNING:tensorflow:Collective ops may deadlock with `save_checkpoints_secs` please use `save_checkpoint_steps` instead. Clearing `save_checkpoint_secs` and setting `save_checkpoint_steps` to 1000 now.
WARNING:tensorflow:Collective ops may deadlock with `save_checkpoints_secs` please use `save_checkpoint_steps` instead. Clearing `save_checkpoint_secs` and setting `save_checkpoint_steps` to 1000 now.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:all_hooks [<tensorflow_estimator.python.estimator.util.DistributedIteratorInitializerHook object at 0x7f2e33513890>, <tensorflow.python.training.basic_session_run_hooks.StopAtStepHook object at 0x7f2e33505c90>, <tensorflow.python.training.basic_session_run_hooks.NanTensorHook object at 0x7f2e30321050>, <tensorflow.python.training.basic_session_run_hooks.LoggingTensorHook object at 0x7f2e303219d0>, <tensorflow.python.training.basic_session_run_hooks.StepCounterHook object at 0x7f2e30202610>, <tensorflow.python.training.basic_session_run_hooks.SummarySaverHook object at 0x7f2e30260bd0>, <tensorflow.python.training.basic_session_run_hooks.CheckpointSaverHook object at 0x7f2e30252390>]
INFO:tensorflow:all_hooks [<tensorflow_estimator.python.estimator.util.DistributedIteratorInitializerHook object at 0x7f2e33513890>, <tensorflow.python.training.basic_session_run_hooks.StopAtStepHook object at 0x7f2e33505c90>, <tensorflow.python.training.basic_session_run_hooks.NanTensorHook object at 0x7f2e30321050>, <tensorflow.python.training.basic_session_run_hooks.LoggingTensorHook object at 0x7f2e303219d0>, <tensorflow.python.training.basic_session_run_hooks.StepCounterHook object at 0x7f2e30202610>, <tensorflow.python.training.basic_session_run_hooks.SummarySaverHook object at 0x7f2e30260bd0>, <tensorflow.python.training.basic_session_run_hooks.CheckpointSaverHook object at 0x7f2e30252390>]
INFO:tensorflow:Creating chief session creator with config: device_filters: "/job:worker/task:1"
allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
    scoped_allocator_optimization: ON
    scoped_allocator_opts {
      enable_op: "CollectiveReduce"
    }
  }
}
experimental {
  collective_group_leader: "/job:worker/replica:0/task:0"
}

INFO:tensorflow:Creating chief session creator with config: device_filters: "/job:worker/task:1"
allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
    scoped_allocator_optimization: ON
    scoped_allocator_opts {
      enable_op: "CollectiveReduce"
    }
  }
}
experimental {
  collective_group_leader: "/job:worker/replica:0/task:0"
}

INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Graph was finalized.
WARNING:tensorflow:From /home/vincent/miniconda3/envs/build/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
WARNING:tensorflow:From /home/vincent/miniconda3/envs/build/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into ./estimator/multiworker/tmp_worker_1/model.ckpt.
INFO:tensorflow:Saving checkpoints for 0 into ./estimator/multiworker/tmp_worker_1/model.ckpt.
2019-11-12 16:35:28.566461: W tensorflow/core/common_runtime/collective_param_resolver_local.cc:182] Collective op allreduce_1/CollectiveReduce: Reduce(Add,Id) got duplicate CompleteGroup calls for group 1 and device /job:worker/replica:0/task:1/device:CPU:0
2019-11-12 16:35:28.566669: W tensorflow/core/common_runtime/collective_param_resolver_local.cc:182] Collective op allreduce/CollectiveReduce_3: Reduce(Add,Id) got duplicate CompleteGroup calls for group 1 and device /job:worker/replica:0/task:1/device:CPU:0
2019-11-12 16:35:28.566938: W tensorflow/core/common_runtime/collective_param_resolver_local.cc:182] Collective op allreduce/CollectiveReduce_5: Reduce(Add,Id) got duplicate CompleteGroup calls for group 1 and device /job:worker/replica:0/task:1/device:CPU:0
2019-11-12 16:35:28.567170: W tensorflow/core/common_runtime/collective_param_resolver_local.cc:182] Collective op allreduce/CollectiveReduce_4: Reduce(Add,Id) got duplicate CompleteGroup calls for group 1 and device /job:worker/replica:0/task:1/device:CPU:0
2019-11-12 16:35:28.571032: W tensorflow/core/common_runtime/collective_param_resolver_local.cc:182] Collective op allreduce/CollectiveReduce_2: Reduce(Add,Id) got duplicate CompleteGroup calls for group 1 and device /job:worker/replica:0/task:1/device:CPU:0
2019-11-12 16:35:28.580905: W tensorflow/core/common_runtime/collective_param_resolver_local.cc:182] Collective op allreduce/CollectiveReduce_1: Reduce(Add,Id) got duplicate CompleteGroup calls for group 1 and device /job:worker/replica:0/task:1/device:CPU:0
2019-11-12 16:35:28.583586: W tensorflow/core/common_runtime/collective_param_resolver_local.cc:182] Collective op allreduce/CollectiveReduce: Reduce(Add,Id) got duplicate CompleteGroup calls for group 1 and device /job:worker/replica:0/task:1/device:CPU:0
INFO:tensorflow:loss = 2.3116875, step = 0
INFO:tensorflow:loss = 2.3116875, step = 0
INFO:tensorflow:loss = 2.303741, step = 100 (2.825 sec)
INFO:tensorflow:loss = 2.303741, step = 100 (2.825 sec)
INFO:tensorflow:global_step/sec: 35.4062
INFO:tensorflow:global_step/sec: 35.4062
INFO:tensorflow:loss = 2.3003964, step = 200 (2.651 sec)
INFO:tensorflow:loss = 2.3003964, step = 200 (2.651 sec)
INFO:tensorflow:global_step/sec: 37.7268
INFO:tensorflow:global_step/sec: 37.7268
INFO:tensorflow:loss = 2.2990692, step = 300 (2.603 sec)
INFO:tensorflow:loss = 2.2990692, step = 300 (2.603 sec)
INFO:tensorflow:global_step/sec: 38.4188
INFO:tensorflow:global_step/sec: 38.4188
INFO:tensorflow:Saving checkpoints for 380 into ./estimator/multiworker/tmp_worker_1/model.ckpt.
INFO:tensorflow:Saving checkpoints for 380 into ./estimator/multiworker/tmp_worker_1/model.ckpt.
INFO:tensorflow:Loss for final step: 2.2996933.
INFO:tensorflow:Loss for final step: 2.2996933.
2019-11-12 16:35:38.170798: W tensorflow/core/common_runtime/eager/context.cc:319] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.

Process finished with exit code 0
